{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    accidents_2015 = pd.read_csv(\"datasets/2015-data/Accidents_2015.csv\", index_col=\"Accident_Index\")\n",
    "    accidents_2016 = pd.read_csv(\"datasets/Accidents_2016.csv\", index_col=\"Accident_Index\")\n",
    "    accidents_all = [accidents_2015, accidents_2016]\n",
    "    return pd.concat(accidents_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#handling missing values\n",
    "def handle_missing_values(accidents_original):\n",
    "    accidents_preprocessed = accidents_original.copy()\n",
    "    accidents_preprocessed.replace(-1, np.NaN, inplace=True)\n",
    "    print(\"Missing values per column \\n\" + str(accidents_preprocessed.isnull().sum()))\n",
    "    print(\"\\nSize before replace \" + str(accidents_preprocessed.shape))\n",
    "    \n",
    "    #find column wise modes\n",
    "    modes = accidents_preprocessed.mode().to_dict(orient='records')[0]\n",
    "    accidents_preprocessed.fillna(modes, inplace=True)\n",
    "    \n",
    "    print(\"\\nVerify missing values per column \\n\" + str(accidents_preprocessed.isnull().sum()))\n",
    "    print(\"\\nSize after replace \" + str(accidents_preprocessed.shape))\n",
    "    return accidents_preprocessed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "round(abs(-7.3898 - (-7)),2)\n",
    "round(abs(1.7578 - (-7)),2)\n",
    "\n",
    "base_longitude = acc['Longitude_X'].min()\n",
    "base_latitide = acc['Latitude_Y'].min()\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "test_df['location'] = acc['Longitude_X'] * acc['Latitude_Y']\n",
    "\n",
    "test_df['new_X'] = acc['Longitude_X'] - base_longitude\n",
    "test_df['new_Y'] = acc['Latitude_Y'] - base_latitide\n",
    "m = test_df['new_X'].max()\n",
    "print(m)\n",
    "test_df['new_loc'] = test_df['new_X'] + test_df['new_Y'] * m\n",
    "\n",
    "test_df.describe()\n",
    "#test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_location(accidents_df):\n",
    "    #accidents_df['Longitude_X'] = accidents_df['Longitude'].apply(lambda l: round(abs(l - (-7)), 2)*100)\n",
    "    #accidents_df['Latitude_Y'] = accidents_df['Latitude'].apply(lambda l: round(abs(l - (49)), 2)*100)\n",
    "    accidents_df['Longitude_X'] = accidents_df['Longitude'].apply(lambda l: round(abs(l - (-7)), 1)*10)\n",
    "    accidents_df['Latitude_Y'] = accidents_df['Latitude'].apply(lambda l: round(abs(l - (49)), 1)*10)\n",
    "\n",
    "    base_longitude = accidents_df['Longitude_X'].min()\n",
    "    base_latitide = accidents_df['Latitude_Y'].min()\n",
    "    accidents_df['Longitude_X_N'] = accidents_df['Longitude_X'] - base_longitude\n",
    "    accidents_df['Latitude_Y_N'] = accidents_df['Latitude_Y'] - base_latitide\n",
    "    \n",
    "    multipier = accidents_df['Longitude_X_N'].max()\n",
    "    accidents_df['Derived_Location'] = accidents_df['Longitude_X_N'] + accidents_df['Latitude_Y_N'] * multipier\n",
    "    #accidents_df['Derived_Location'] = accidents_df['Longitude_X'] * accidents_df['Latitude_Y']\n",
    "    #print(accidents_df.describe())\n",
    "    return accidents_df\n",
    "\n",
    "# acc = process_location(accidents_original)\n",
    "# acc.filter(['Longitude', 'Latitude', 'Longitude_X', 'Latitude_Y', 'Derived_Location']).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# catagorize  the time into 3 hour slots\n",
    "def process_time(accidents_df):\n",
    "    accidents_df['Time_Slot'] = accidents_df['Time'].apply(lambda t: int(str(t).split(':', 1)[0])//3)\n",
    "    return accidents_df\n",
    "\n",
    "\n",
    "#print(int('4:34'.split(':', 1)[0])//3)\n",
    "# val = df['Time']['2016010000006'].split(':', 1)[0]\n",
    "# print(int(val) // 3)\n",
    "\n",
    "\n",
    "# df['Time_Slot'] = df['Time']\n",
    "# print(df['Time'].describe())\n",
    "#df = load_data()\n",
    "#print(df['Time']['2016010000006'].split(':', 1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_columns(accidents_df):\n",
    "    return accidents_df.filter(['Accident_Severity', 'Day_of_Week', 'Road_Type', 'Speed_limit',\n",
    "                                'Junction_Detail', 'Junction_Control', 'Light_Conditions', \n",
    "                                'Weather_Conditions', 'Road_Surface_Conditions',\n",
    "                                'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities',\n",
    "                                'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
    "                                'Derived_Location', 'Time_Slot'],\n",
    "                                axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anilc/Library/Python/3.6/lib/python/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anilc/Library/Python/3.6/lib/python/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (31) have mixed types. Specify dtype option on import or set low_memory=False.\n  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns : \n['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude', 'Police_Force', 'Accident_Severity', 'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week', 'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)', '1st_Road_Class', '1st_Road_Number', 'Road_Type', 'Speed_limit', 'Junction_Detail', 'Junction_Control', '2nd_Road_Class', '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident', 'LSOA_of_Accident_Location']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column \nLocation_Easting_OSGR                              34\nLocation_Northing_OSGR                             34\nLongitude                                          34\nLatitude                                           34\nPolice_Force                                        0\nAccident_Severity                                   0\nNumber_of_Vehicles                                  0\nNumber_of_Casualties                                0\nDate                                                0\nDay_of_Week                                         0\nTime                                               20\nLocal_Authority_(District)                          0\nLocal_Authority_(Highway)                           0\n1st_Road_Class                                      0\n1st_Road_Number                                     0\nRoad_Type                                           1\nSpeed_limit                                        37\nJunction_Detail                                   107\nJunction_Control                               112693\n2nd_Road_Class                                 113592\n2nd_Road_Number                                  1322\nPedestrian_Crossing-Human_Control                 325\nPedestrian_Crossing-Physical_Facilities           758\nLight_Conditions                                   13\nWeather_Conditions                                 13\nRoad_Surface_Conditions                          1053\nSpecial_Conditions_at_Site                        611\nCarriageway_Hazards                               641\nUrban_or_Rural_Area                                 0\nDid_Police_Officer_Attend_Scene_of_Accident         8\nLSOA_of_Accident_Location                       17248\ndtype: int64\n\nSize before replace (276677, 31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nVerify missing values per column \nLocation_Easting_OSGR                          0\nLocation_Northing_OSGR                         0\nLongitude                                      0\nLatitude                                       0\nPolice_Force                                   0\nAccident_Severity                              0\nNumber_of_Vehicles                             0\nNumber_of_Casualties                           0\nDate                                           0\nDay_of_Week                                    0\nTime                                           0\nLocal_Authority_(District)                     0\nLocal_Authority_(Highway)                      0\n1st_Road_Class                                 0\n1st_Road_Number                                0\nRoad_Type                                      0\nSpeed_limit                                    0\nJunction_Detail                                0\nJunction_Control                               0\n2nd_Road_Class                                 0\n2nd_Road_Number                                0\nPedestrian_Crossing-Human_Control              0\nPedestrian_Crossing-Physical_Facilities        0\nLight_Conditions                               0\nWeather_Conditions                             0\nRoad_Surface_Conditions                        0\nSpecial_Conditions_at_Site                     0\nCarriageway_Hazards                            0\nUrban_or_Rural_Area                            0\nDid_Police_Officer_Attend_Scene_of_Accident    0\nLSOA_of_Accident_Location                      0\ndtype: int64\n\nSize after replace (276677, 31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nPost preprocessing columns : ['Accident_Severity', 'Day_of_Week', 'Road_Type', 'Speed_limit', 'Junction_Detail', 'Junction_Control', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Derived_Location', 'Time_Slot']\n\n\nDescribe \n       Accident_Severity    Day_of_Week      Road_Type    Speed_limit  \\\ncount      276677.000000  276677.000000  276677.000000  276677.000000   \nmean            2.825121       4.105296       5.176393      38.060012   \nstd             0.410160       1.914275       1.652676      13.971795   \nmin             1.000000       1.000000       1.000000       0.000000   \n25%             3.000000       2.000000       6.000000      30.000000   \n50%             3.000000       4.000000       6.000000      30.000000   \n75%             3.000000       6.000000       6.000000      40.000000   \nmax             3.000000       7.000000       9.000000      70.000000   \n\n       Junction_Detail  Junction_Control  Light_Conditions  \\\ncount    276677.000000     276677.000000     276677.000000   \nmean          2.259107          3.776823          1.967673   \nstd           2.499343          0.638623          1.665259   \nmin           0.000000          0.000000          1.000000   \n25%           0.000000          4.000000          1.000000   \n50%           2.000000          4.000000          1.000000   \n75%           3.000000          4.000000          4.000000   \nmax           9.000000          4.000000          7.000000   \n\n       Weather_Conditions  Road_Surface_Conditions  \\\ncount       276677.000000            276677.000000   \nmean             1.532151                 1.302938   \nstd              1.606421                 0.553956   \nmin              1.000000                 1.000000   \n25%              1.000000                 1.000000   \n50%              1.000000                 1.000000   \n75%              1.000000                 2.000000   \nmax              9.000000                 5.000000   \n\n       Pedestrian_Crossing-Human_Control  \\\ncount                      276677.000000   \nmean                            0.010344   \nstd                             0.135561   \nmin                             0.000000   \n25%                             0.000000   \n50%                             0.000000   \n75%                             0.000000   \nmax                             2.000000   \n\n       Pedestrian_Crossing-Physical_Facilities  Special_Conditions_at_Site  \\\ncount                            276677.000000               276677.000000   \nmean                                  0.834421                    0.094381   \nstd                                   1.927883                    0.675128   \nmin                                   0.000000                    0.000000   \n25%                                   0.000000                    0.000000   \n50%                                   0.000000                    0.000000   \n75%                                   0.000000                    0.000000   \nmax                                   8.000000                    7.000000   \n\n       Carriageway_Hazards  Derived_Location      Time_Slot  \ncount        276677.000000     276677.000000  276677.000000  \nmean              0.060937       2308.835429       4.176263  \nstd               0.563632       1228.392234       1.714549  \nmin               0.000000          6.000000       0.000000  \n25%               0.000000       1456.000000       3.000000  \n50%               0.000000       1903.000000       4.000000  \n75%               0.000000       3092.000000       5.000000  \nmax               7.000000       9455.000000       7.000000  \n"
     ]
    }
   ],
   "source": [
    "#driver program\n",
    "\n",
    "accidents_original = load_data()\n",
    "print(\"Original columns : \\n\" + str(list(accidents_original.columns.values)))\n",
    "\n",
    "accidents_preprocessed = handle_missing_values(accidents_original)\n",
    "\n",
    "accidents_preprocessed = process_location(accidents_preprocessed)\n",
    "\n",
    "accidents_preprocessed = process_time(accidents_preprocessed)\n",
    "\n",
    "accidents_preprocessed = filter_columns(accidents_preprocessed)\n",
    "\n",
    "print(\"\\n\\nPost preprocessing columns : \" + str(list(accidents_preprocessed.columns.values)))\n",
    "print(\"\\n\\nDescribe \\n\" + str(accidents_preprocessed.describe()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_categorical_values(accidents_df):\n",
    "    \n",
    "    cols_to_transform = ['Day_of_Week', 'Road_Type', 'Speed_limit', 'Junction_Detail', 'Junction_Control',\n",
    "                         'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions',\n",
    "                         'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities',\n",
    "                         'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
    "                         'Derived_Location', 'Time_Slot']\n",
    "    \n",
    "    return pd.get_dummies(accidents_df, columns = cols_to_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accident_Severity']\n"
     ]
    }
   ],
   "source": [
    "accidents_onehotencoded = transform_categorical_values(accidents_preprocessed)\n",
    "\n",
    "input = accidents_onehotencoded.drop(['Accident_Severity'], axis=1)\n",
    "labels = accidents_onehotencoded.filter(['Accident_Severity'], axis=1)\n",
    "\n",
    "#print(list(input.columns.values))\n",
    "\n",
    "print(list(labels.columns.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TBD\n",
    "\n",
    "# tbd = accidents_original.filter(['Urban_or_Rural_Area'])\n",
    "# print(tbd['Pedestrian_Crossing-Human_Control'].value_counts())\n",
    "# tbd = tbd[tbd['Pedestrian_Crossing-Human_Control'] == -1]\n",
    "# print(tbd.shape)\n",
    "# \n",
    "# #print(tbd.describe())\n",
    "# \n",
    "# ignored = accidents_original.filter(['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Police_Force',\n",
    "#                                      'Number_of_Vehicles', 'Number_of_Casualties',\n",
    "#                                      'Local_Authority_(District)', 'Local_Authority_(Highway)', \n",
    "#                                      '1st_Road_Class', '1st_Road_Number', '2nd_Road_Class', '2nd_Road_Number',\n",
    "#                                      'Did_Police_Officer_Attend_Scene_of_Accident', 'LSOA_of_Accident_Location',\n",
    "#                                      'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n2\n"
     ]
    }
   ],
   "source": [
    "#redundant \n",
    "# print(\"missing values i.e. -1\")\n",
    "# print(accidents_filtered[accidents_filtered['Road_Type'] == -1].shape) #1\n",
    "# print(accidents_filtered[accidents_filtered['Junction_Detail'] == -1].shape) #106\n",
    "# print(accidents_filtered[accidents_filtered['Junction_Control'] == -1].shape) #56623\n",
    "# print(accidents_filtered[accidents_filtered['Light_Conditions'] == -1].shape) #13\n",
    "# print(accidents_filtered[accidents_filtered['Weather_Conditions'] == -1].shape) #13\n",
    "# print(accidents_filtered[accidents_filtered['Road_Surface_Conditions'] == -1].shape) #13\n",
    "# \n",
    "# print(\"\\nvalue counts\")\n",
    "# print(accidents_filtered['Junction_Control'].value_counts())\n",
    "# print(accidents_filtered['Light_Conditions'].value_counts())\n",
    "# print(accidents_filtered['Weather_Conditions'].value_counts())\n",
    "# print(accidents_filtered['Road_Surface_Conditions'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_train.shape : (207507, 3043)\nlabels_train.shape : (207507, 1)\ninput_test.shape : (69170, 3043)\nlabels_test.shape : (69170, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "input_train, input_test, labels_train, labels_test = train_test_split(input, labels, \n",
    "                                                                      test_size=0.25)\n",
    "print(\"input_train.shape : \" + str(input_train.shape))\n",
    "print(\"labels_train.shape : \" + str(labels_train.shape))\n",
    "print(\"input_test.shape : \" + str(input_test.shape))\n",
    "print(\"labels_test.shape : \" + str(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l2', C=1000, max_iter=1000)\n",
    "\n",
    "classifier.fit(input_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_metrics(classifier, input, labels_actuals):\n",
    "    labels_predicts = classifier.predict(input)\n",
    "\n",
    "    print(\"Accuracy : \" + str(metrics.accuracy_score(labels_actuals, labels_predicts)))\n",
    "    print(\"Precision : \" + str(metrics.precision_score(labels_actuals, labels_predicts, average=None)))\n",
    "    print(\"Recall : \" + str(metrics.recall_score(labels_actuals, labels_predicts, average=None)))\n",
    "    print(\"F1 score : \" + str(metrics.f1_score(labels_actuals, labels_predicts, average=None)))\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(metrics.confusion_matrix(labels_actuals, labels_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8321805006587615\nPrecision : [0.75       0.64560711 0.83398176]\nRecall : [0.03944485 0.03768366 0.99640065]\nF1 score : [0.07494795 0.0712108  0.90798509]\nConfusion Matrix : \n[[   54    40  1275]\n [   11   654 16690]\n [    7   319 90246]]\n\nMetrics for test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8239707227813358\nPrecision : [0.         0.28629032 0.82953873]\nRecall : [0.         0.01624714 0.99182465]\nF1 score : [0.         0.03074924 0.90345175]\nConfusion Matrix : \n[[    0     6   320]\n [    7    71  4292]\n [   14   171 22444]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for training data\")\n",
    "print_metrics(classifier, input_train, labels_train)\n",
    "\n",
    "print(\"\\nMetrics for test data\")\n",
    "print_metrics(classifier, input_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=100,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=100)\n",
    "dt_classifier.fit(input_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8968397745571659\nPrecision : [0.97016706 0.95825296 0.89182806]\nRecall : [0.59386413 0.40074906 0.99647794]\nF1 score : [0.73674671 0.5651485  0.94125315]\nConfusion Matrix : \n[[  813     0   556]\n [    9  6955 10391]\n [   16   303 90253]]\n\nMetrics for test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7982799634034766\nPrecision : [0.02678571 0.19227609 0.82997384]\nRecall : [0.00920245 0.05354691 0.95346679]\nF1 score : [0.01369863 0.08376589 0.88744473]\nConfusion Matrix : \n[[    3    17   306]\n [   22   234  4114]\n [   87   966 21576]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for training data\")\n",
    "print_metrics(dt_classifier, input_train, labels_train)\n",
    "\n",
    "print(\"\\nMetrics for test data\")\n",
    "print_metrics(dt_classifier, input_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anilc/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8372006727483892\nPrecision : [0.         0.         0.83720067]\nRecall : [0. 0. 1.]\nF1 score : [0.         0.         0.91138729]\nConfusion Matrix : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0   2465]\n [     0      0  31317]\n [     0      0 173725]]\n\nMetrics for test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8367500361428365\nPrecision : [0.         0.         0.83675004]\nRecall : [0. 0. 1.]\nF1 score : [0.         0.         0.91112021]\nConfusion Matrix : \n[[    0     0   846]\n [    0     0 10446]\n [    0     0 57878]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=20,\n",
    "                                       max_depth=100,\n",
    "                                       min_samples_split=5,\n",
    "                                       min_samples_leaf=5)\n",
    "rf_classifier.fit(input_train, labels_train)\n",
    "\n",
    "print(\"Metrics for training data\")\n",
    "print_metrics(rf_classifier, input_train, labels_train)\n",
    "\n",
    "print(\"\\nMetrics for test data\")\n",
    "print_metrics(rf_classifier, input_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9824787732396428\nPrecision : [0.98964143 0.98811694 0.98140792]\nRecall : [0.94233687 0.90472627 0.99796925]\nF1 score : [0.96541003 0.94458469 0.9896193 ]\nConfusion Matrix : \n[[ 1242    12    64]\n [    6 15716  1649]\n [    7   177 90423]]\n\nMetrics for test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8145654162854529\nPrecision : [0.04347826 0.17276423 0.82700485]\nRecall : [0.00265252 0.01952228 0.98132247]\nF1 score : [0.005      0.03508048 0.89757914]\nConfusion Matrix : \n[[    1     3   373]\n [    4    85  4265]\n [   18   404 22172]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(100,20,10))\n",
    "nn_classifier.fit(input_train, labels_train)\n",
    "\n",
    "print(\"Metrics for training data\")\n",
    "print_metrics(rf_classifier, input_train, labels_train)\n",
    "\n",
    "print(\"\\nMetrics for test data\")\n",
    "print_metrics(rf_classifier, input_test, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
